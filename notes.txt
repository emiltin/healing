when you run cloud start locally:
the ideal.rb file is read
cloud object structure now has all info, including number of nodes, and provider
nodes are launched
nodes are bootstrapped
files are uploaded
ideal.rb are run on the nodes


somehow the nodes need to know what cloud they're in. they need an identity. is someone going to tell them? or should they decide themselves? [update: in ideal.rb, each clouds is assigned an uuid, which is then stored on the nodes at /healing/cloud_uuid]

ideal.rb describe the cloud. it can be read on the host to provision and bootstrap the cloud. it can also be read on the node to do the actual configuration. this requires that the node knows what subcloud it's in.


what happens when the names of the clouds change - how does nodes know what cloud they belong to then? [update: using uuids solve this this problem.]



each cloud has a uuid, which is set by the user, and should not be changed.
when launching nodes, the uuid is stored on the nodes. that way each node can read ideal.rb and know what cloud it belongs to.
all nodes in a cloud are configured exactly similarly. if a special node is neeed, it should be in it's own sub cloud.


a recipe folder is also pushed, so individual recipes can be run on a specific cloud.



ok, i can now heal a remote node, which is great!
next steps:
-make the ec2 provider real, so we can start and terminate instances, and heal them MOSTLY DONE
-cache node info locally DONE update: only caching id->cloud_uuid pairs, everything else is read each time from the provider
-separate the lib and user files, so ideal.rb can be in a different location
-handle uploading of recipes
-bootstrapping nodes
-link resource
-repo resource
-package repo
-providers for resources?
-rails resource?
-ssh to multiple instances. threads or sequentially? handle output

next up: match map against ideal, and launch/terminate instances as needed


how to organize clouds, healer and mapper? what contains what?
it's important that the code running on the instances doesn't require the provisioner, since it requires the ec2 gem which might not be installed.
should clouds be able to provision themselves? or is it done from the 'outside' by the healer?
is provisioning ever done from an instances? yeah it might be if the clouds is able to autosscale.


cool, i can now start a cloud and the instance will be launched and healed, all in one go!
is the cloud map really needed? do we care what instances are in hat cloud? we can just ask each instance if needed. it's a bit slower, but probably more robust? hmm in fact the map is quite robust, because we do sync with the list of instances each time to use it. as long as cloud uuid's don't change on the instances it should be valid, and provide a small speedup.. but it adds code complexity. simpler to simply build the map each time.

todo: add new instances to known_hosts file automatically. [instead, using Net::SSH, and we can pass :paranoid => false


cloud: describes the ideal.
cloud provider: launching/term/desc instances
healer: orchestrates healing process
map: ? can this just be handles by the cloud and it's list of instances?
key: key file

healer - cloud - subclouds - instances


say a cloudsystem is missing 10 instance, in 3 subclouds
we launch 10 instances.
then we want to divide the pool of 10 new instances to the subclouds that wanted them

alright! i can now pretty much launch a cloud with multiple instances!
todo: ruby rsync, to avoid ssh warnings in the terminal [update: not needed. simply pass some options to ssh inside rsycn instead]

coool.. getting clean runs when starting and healing clouds. works with subclouds too.
todo: pruning clouds. bootstrapping. improved file locations and separate user files

